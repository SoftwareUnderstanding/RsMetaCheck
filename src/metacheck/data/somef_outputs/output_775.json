{"somef_provenance": {"somef_version": "0.9.12", "somef_schema_version": "1.0.0", "date": "2025-11-17 14:42:40"}, "code_repository": [{"result": {"value": "https://github.com/MyWebIntelligence/mwiR", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "https://github.com/MyWebIntelligence/mwiR", "type": "Url"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, {"result": {"value": "https://github.com/MyWebIntelligence/mwiR", "type": "Url"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "owner": [{"result": {"value": "MyWebIntelligence", "type": "Organization"}, "confidence": 1, "technique": "GitHub_API"}], "date_created": [{"result": {"value": "2024-06-20T17:58:47Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "2023-05-19", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "date_updated": [{"result": {"value": "2025-09-19T15:22:34Z", "type": "Date"}, "confidence": 1, "technique": "GitHub_API"}], "description": [{"result": {"value": "The My Web Intelligence Package for R", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "My Web Intelligence (MWI) is a project designed to meet the growing need for tools and methodologies in the field of digital methods in social sciences and information and communication sciences (ICS). The main objective is to map the digital ecosystem to identify key actors, assess their influence, and analyze their discourses and interactions. This project addresses the increasing centrality of digital information and interactions in various fields, including health, politics, culture, and beyond.", "type": "String", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, {"result": {"value": "My Web Intelligence (MWI) is an R package designed to address the growing need for tools and methodologies in the field of digital methods within social sciences and information and communication sciences. The main objective is to map the digital ecosystem to identify key actors, assess their influence, and analyze their discourse and interactions.", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}, {"result": {"value": "    listlands(\"AIWork\")\n\nThe `listlands()` function lists all lands or projects that have been\ncreated. By specifying the project name \u201cAIWork\u201d, it verifies that the\nproject has been successfully created.\n\n-   `land_name`: A string specifying the name of the land to list. If\n    `NULL`, all lands are listed. Default is `NULL`.\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n", "type": "Text_excerpt", "original_header": "5. Verify the Project Creation", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"type": "Text_excerpt", "value": "My Web Intelligence (MWI) is a project designed to meet the growing need\nfor tools and methodologies in the field of digital methods in social\nsciences and information and communication sciences (ICS). The main\nobjective is to map the digital ecosystem to identify key actors, assess\ntheir influence, and analyze their discourses and interactions. This\nproject addresses the increasing centrality of digital information and\ninteractions in various fields, including health, politics, culture, and\nbeyond.\n \n", "original_header": "Purpose of My Web Intelligence"}, "confidence": 0.9804810201780737, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"type": "Text_excerpt", "value": "Amar Lakel is a researcher in information and communication sciences,\nspecializing in digital methods applied to social studies. He is\ncurrently a member of the MICA laboratory (Mediation, Information,\nCommunication, Arts) at the University of Bordeaux Montaigne. His work\nfocuses on the analysis of online discourse, mapping digital ecosystems,\nand the impact of digital technologies on social and cultural practices.\n \n", "original_header": "About the Author"}, "confidence": 0.9679607497380824, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"type": "Text_excerpt", "value": "The research protocol of MWI relies on a combination of quantitative and\nqualitative methods: \n1.  **Data Extraction and Archiving**: Using crawl technologies to\n    collect data from the web.\n2.  **Data Qualification and Annotation**: Applying algorithms to\n    analyze, classify, and annotate the data.\n3.  **Data Visualization**: Developing dashboards and relational maps to\n    interpret the results. \nThe MWI project utilizes techniques from the sociology of controversies,\nsocial network analysis, and text mining methods to: \n-   Analyze the strategic positions of speakers in a heterogeneous and\n    complex digital corpus.\n-   Identify and understand the dynamics of online discourses.\n-   Map the relationships between different actors and their respective\n    influences.\n \n", "original_header": "Methodology"}, "confidence": 0.9297842776678669, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"type": "Text_excerpt", "value": "The R package developed within the framework of My Web Intelligence is\ndesigned to: - Facilitate the replication of analyses conducted in the\nproject. - Enable the extension of developed methods and tools for other\nresearch. - Provide researchers and professionals with a powerful tool\nto understand and manage the dynamics of online information. \n-   **Project Management**: Tools to initiate and manage web exploration\n    projects.\n-   **Data Extraction**: Functions to crawl the web and extract data\n    corpora.\n-   **Analysis and Annotation**: Algorithms to analyze and annotate\n    extracted data.\n-   **Visualization**: Dashboards and maps to visualize relationships\n    between actors and discourses.\n \n", "original_header": "Development of the R Package"}, "confidence": 0.9890663168649558, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"type": "Text_excerpt", "value": "My Web Intelligence is an integrative project aimed at transforming how\nwe understand and analyze digital information across various fields in\nsocial sciences and ICS. By combining innovative methodologies and\nadvanced technological tools, MWI offers new perspectives on digital\ndynamics and proposes solutions to better understand online interactions\nand discourses. The R package developed from this project is an\nessential tool for researchers and practitioners, enabling them to fully\nexploit web data for in-depth and relevant analyses.\n \n", "original_header": "Conclusion"}, "confidence": 0.9872859314386027, "technique": "supervised_classification", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}], "name": [{"result": {"value": "mwiR", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "mwiR", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "full_name": [{"result": {"value": "MyWebIntelligence/mwiR", "type": "String"}, "confidence": 1, "technique": "GitHub_API"}], "issue_tracker": [{"result": {"value": "https://api.github.com/repos/MyWebIntelligence/mwiR/issues", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "https://github.com/MyWebIntelligence/mwiR/issues", "type": "Url"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, {"result": {"value": "https://github.com/MyWebIntelligence/mwiR/issues", "type": "Url"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "forks_url": [{"result": {"value": "https://api.github.com/repos/MyWebIntelligence/mwiR/forks", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}], "stargazers_count": [{"result": {"value": 3, "type": "Number"}, "confidence": 1, "technique": "GitHub_API"}], "download_url": [{"result": {"value": "https://github.com/MyWebIntelligence/mwiR/releases", "type": "Url"}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "https://github.com/MyWebIntelligence/mwiR/archive/refs/tags/v0.8.0-beta.zip", "type": "Url"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "programming_languages": [{"result": {"value": "R", "name": "R", "type": "Programming_language", "size": 186777}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"value": "Rez", "name": "Rez", "type": "Programming_language", "size": 64}, "confidence": 1, "technique": "GitHub_API"}, {"result": {"name": "R", "value": "R", "type": "Programming_language", "url": "https://www.r-project.org"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}, {"result": {"name": "Python", "value": "Python", "type": "Programming_language", "url": "https://www.python.org"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "license": [{"result": {"value": "# MIT License\n\nCopyright (c) 2024 mwiR authors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n", "type": "File_dump", "name": "MIT License", "spdx_id": "MIT"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/LICENSE.md"}, {"result": {"value": "MIT + file LICENSE", "type": "String", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, {"result": {"value": "https://spdx.org/licenses/MIT", "type": "License", "identifier": "https://spdx.org/licenses/https://spdx.org/licenses/MIT", "spdx_id": "https://spdx.org/licenses/MIT"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "readme_url": [{"result": {"value": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}, {"result": {"value": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.md", "type": "Url"}, "confidence": 1, "technique": "file_exploration"}], "has_build_file": [{"result": {"value": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION", "type": "Url", "format": "description"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}], "has_package_file": [{"result": {"value": "DESCRIPTION", "type": "Url", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}], "package_id": [{"result": {"value": "mwiR", "type": "String", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}], "version": [{"result": {"value": "0.2.1", "type": "String", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/DESCRIPTION"}, {"result": {"value": "0.9.0", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "application_domain": [{"result": {"value": "Research Tool", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}, {"result": {"type": "String", "value": "Semantic web"}, "confidence": 0.9436336083311225, "technique": "supervised_classification"}], "date_published": [{"result": {"value": "2024", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "keywords": [{"result": {"value": ["digital methods", "web intelligence", "social sciences", "data mining", "network analysis", "text analysis", "internet sociology", "R package"], "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "citation": [{"result": {"value": "My Web Intelligence: Challenges of Heterogeneous Digital Corpora", "title": "My Web Intelligence: Challenges of Heterogeneous Digital Corpora", "type": "Scholarly_article", "url": "https://hal.science/hal-03233584", "date_published": "2021", "doi": "hal-03233584"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "development_status": [{"result": {"value": "beta", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "identifier": [{"result": {"value": "https://doi.org/10.5281/zenodo.1234567", "type": "String"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "authors": [{"result": {"value": "Amar Lakel", "type": "String", "email": "amar.lakel@u-bordeaux-montaigne.fr", "affiliation": "MICA Labo, Universit\u00e9 de Bordeaux Montaigne", "identifier": "https://orcid.org/0000-0002-1825-0097"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "requirements": [{"result": {"value": "R (>= 4.0.0)", "type": "Software_application"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}, {"result": {"value": "Python (>= 3.6)", "type": "Software_application"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}, {"result": {"value": "trafilatura", "name": "trafilatura", "type": "Software_application"}, "confidence": 1, "technique": "code_parser", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/codemeta.json"}], "installation": [{"result": {"value": "# Guide d\u2019Installation \u2013 mwiR\n\nCe document explique comment installer et configurer le package **mwiR** ainsi que toutes ses d\u00e9pendances, pour un usage en d\u00e9veloppement ou en production.\n\n---\n\n## 1. Pr\u00e9requis syst\u00e8me\n\n- **R** (version \u2265 4.0 recommand\u00e9e)\n- **RStudio** (optionnel, mais recommand\u00e9 pour le d\u00e9veloppement)\n- **Git** (pour cloner le d\u00e9p\u00f4t et g\u00e9rer le versionnement)\n- **Python 3** (pour l\u2019extraction de contenu web avec Trafilatura)\n- **SQLite** (g\u00e9n\u00e9ralement inclus avec R, sinon installer via votre gestionnaire de paquets)\n\n### Installation des d\u00e9pendances syst\u00e8me sous Ubuntu/Debian\n\n```bash\nsudo apt update\nsudo apt install r-base r-base-dev git python3 python3-pip sqlite3\n```\n\n### Installation sous macOS (avec Homebrew)\n\n```bash\nbrew install --cask r rstudio\nbrew install git python3 sqlite3\n```\n\n---\n\n## 2. Installation des d\u00e9pendances R\n\nOuvrez R ou RStudio, puis ex\u00e9cutez\u00a0:\n\n```r\ninstall.packages(c(\n  \"devtools\", \"testthat\", \"roxygen2\", \"DBI\", \"RSQLite\", \"httr\", \"jsonlite\", \"dplyr\", \"stringr\"\n))\n```\n\n**Remarque\u00a0:**  \nCertaines d\u00e9pendances peuvent \u00e9voluer. V\u00e9rifiez le fichier `DESCRIPTION` pour la liste \u00e0 jour.\n\n---\n\n## 3. Installation de Trafilatura (Python)\n\nTrafilatura est utilis\u00e9 pour l\u2019extraction de texte web. Installez-le via pip\u00a0:\n\n```bash\npip3 install trafilatura\n```\n\n**V\u00e9rification\u00a0:**\n\n```bash\npython3 -c \"import trafilatura; print(trafilatura.__version__)\"\n```\n\n---\n\n## 4. Installation du package mwiR\n\n### Depuis le d\u00e9p\u00f4t Git (d\u00e9veloppement)\n\n```bash\ngit clone <url_du_depot>\ncd <dossier_du_projet>\ndevtools::load_all(\".\")\n```\n\n### Depuis une archive (utilisateur)\n\nT\u00e9l\u00e9chargez et d\u00e9compressez l\u2019archive, puis\u00a0:\n\n```r\ninstall.packages(\"chemin/vers/mwiR.tar.gz\", repos = NULL, type = \"source\")\n```\n\n---\n\n## 5. Configuration initiale\n\n- Lancez RStudio et ouvrez le projet `mwiR.Rproj`.\n- Ex\u00e9cutez la fonction d\u2019initialisation\u00a0:\n\n```r\nlibrary(mwiR)\ninitmwi()\n```\n\n- V\u00e9rifiez la cr\u00e9ation de la base `mwi.db` dans le dossier `extdata/` ou \u00e0 la racine.\n\n---\n\n## 6. (Optionnel) Configuration de SerpAPI\n\nPour utiliser la recherche d\u2019URLs via SerpAPI, cr\u00e9ez un compte sur [serpapi.com](https://serpapi.com/), r\u00e9cup\u00e9rez votre cl\u00e9 API et configurez-la dans votre environnement R\u00a0:\n\n```r\nSys.setenv(SERPAPI_KEY = \"votre_cle_api\")\n```\n\n---\n\n## 7. V\u00e9rification de l\u2019installation\n\n- Lancez les tests unitaires\u00a0:\n\n```r\ndevtools::test()\n```\n\n- V\u00e9rifiez que toutes les fonctions principales s\u2019ex\u00e9cutent sans erreur\u00a0:\n\n```r\nlibrary(mwiR)\nlistlands()\n```\n\n---\n\n## 8. Probl\u00e8mes courants et solutions\n\n- **Erreur \u201cpackage \u2018xxx\u2019 is not available\u201d**\u00a0: V\u00e9rifiez la version de R et la connexion internet.\n- **Probl\u00e8me avec Trafilatura**\u00a0: V\u00e9rifiez l\u2019installation Python et le chemin d\u2019acc\u00e8s \u00e0 Python dans R (`reticulate::py_config()`).\n- **Base SQLite non trouv\u00e9e**\u00a0: Relancez `initmwi()` ou v\u00e9rifiez les permissions d\u2019\u00e9criture.\n- **Tests qui \u00e9chouent**\u00a0: V\u00e9rifiez que toutes les d\u00e9pendances sont install\u00e9es et \u00e0 jour.\n\n---\n\n## 9. D\u00e9sinstallation\n\nPour supprimer le package et ses d\u00e9pendances\u00a0:\n\n```r\nremove.packages(\"mwiR\")\n# Supprimez manuellement le dossier du projet et la base mwi.db si besoin\n```\n\n---\n\n## 10. Ressources compl\u00e9mentaires\n\n- [Documentation R Packages](https://r-pkgs.org/)\n- [Trafilatura](https://trafilatura.readthedocs.io/en/latest/)\n- [SerpAPI](https://serpapi.com/)\n- [SQLite](https://www.sqlite.org/docs.html)\n\n---\n\n**En cas de difficult\u00e9, consultez le README.md ou contactez le mainteneur du projet.**\n", "type": "File_dump"}, "confidence": 1, "technique": "file_exploration", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/rules/Install.md"}, {"result": {"value": "You can install the development version of mwiR from\n[GitHub](https://github.com/) with:\n\n   \n", "type": "Text_excerpt", "original_header": "Installation", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "This is a basic example which shows you how to solve a common problem:\n\n    install.packages(\"remotes\")  # si n\u00e9cessaire\n    remotes::install_git(\"https://github.com/MyWebIntelligence/mwiR.git\")\n\n    library(mwiR)\n\n\nTrafilatura is a python package necessary library for using this package.\nIf it is not already installed, you can install it using the following code in your terminal console:\n\npip install trafilatura\n\nFor 'Enter your SERP API key or press Enter:'\nThe serp_api function is a future feature. For now, you can just press Enter.\nIn future versions, this feature will allow the use of an API key to interact with search engine results pages (SERP).\n", "type": "Text_excerpt", "original_header": "Project (\u2018land\u2019) Setup", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    db_setup()\n\n\nThe `db_setup()` function sets up the database needed for storing and\nmanaging the data collected during the research project. It initializes\nthe necessary database schema and ensures that the database is ready for\ndata insertion and retrieval.\n\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n", "type": "Text_excerpt", "original_header": "2. Set Up the Database", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}], "support": [{"result": {"value": "**Diverse Cases**\n\n1.  **Health Information**\n\n-   **Asthma and Diabetes in Children**: Studies of online discourses\n    related to these diseases to identify influential actors, understand\n    their positions, and evaluate their impact on patients\u2019 perceptions\n    and behaviors. [Source](https://journals.openedition.org/rfsic/8376)\n\n2.  **Online Political Controversy**\n\n-   **Juan Branco Project**: Analysis of discourses and influence\n    surrounding the public figure Juan Branco, exploring the dynamics of\n    positioning and controversy.\n    [Source](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4584133)\n\n3.  **Research Sociology**\n\n-   **Digital Humanities**: Studies on the impact of digital\n    technologies on humanities and social sciences, including how\n    researchers use the web to disseminate and discuss their work.\n    [Source](https://hal.science/hal-02485370)\n\n**Results and Impact**\n\nThe results of these studies show that online discourses play a crucial\nrole in shaping opinions and behaviors in various fields. They also\nhighlight the importance for researchers and professionals to actively\nengage in these discussions to promote reliable and scientifically\nvalidated information.\n", "type": "Text_excerpt", "original_header": "Case Studies", "parent_header": ["mwiR 0.9.0 (Beta) The R Package of My Web Intelligence Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "In this step-by-step guide, we will walk through the initial setup and\nexecution of a research project using the My Web Intelligence (MWI)\nmethod. This method allows researchers to analyze the impact of various\nfactors, such as AI on work, by collecting and organizing web data. Here\nis a breakdown of the R script provided:\n", "type": "Text_excerpt", "original_header": "Step 1: Creating the Research Project", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    initmwi()\n\n\n\nThe `initmwi()` function initializes the My Web Intelligence environment\nby loading all necessary packages and setting up the environment for\nfurther operations. This function ensures that all dependencies and\nconfigurations are correctly initialized.\n", "type": "Text_excerpt", "original_header": "1. Load the Required Packages", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    create_land(name = \"AIWork\", desc = \"Impact of AI on work\", lang=\"en\")\n\n\nThe `create_land()` function creates a new research project, referred to\nas a \u201cland\u201d in MWI terminology. This land will serve as the container\nfor all data and analyses related to the project.\n\n-   `name`: A string specifying the name of the land.\n-   `desc`: A string providing a description of the land.\n-   `lang`: A string specifying the language of the land. Default is\n    `\"en\"`.\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n", "type": "Text_excerpt", "original_header": "3. Create a Research Project (Land)", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    addterm(\"AIWork\", \"AI, artificial intelligence, work, employment, job, profession, labor market\")\n\nThe `addterm()` function adds search terms to the project. These terms\nwill be used to crawl and collect relevant web data.\n\n-   `land_name`: A string specifying the name of the land.\n-   `terms`: A comma-separated string of terms to add.\n", "type": "Text_excerpt", "original_header": "4. Add Search Terms", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    addurl(\"AIWork\", urls = \"https://www.fr.adp.com/rhinfo/articles/2022/11/la-disparition-de-certains-metiers-est-elle-a-craindre.aspx\")\n\n\nThe `addurl()` function adds URLs to the project. These URLs point to\nweb pages that contain relevant information for the research.\n\n-   `land_name`: A string specifying the name of the land.\n-   `urls`: A comma-separated string of URLs to add. Default is `NULL`.\n-   `path`: A string specifying the path to a file containing URLs.\n    Default is `NULL`.\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n\nAlternatively, URLs can be added using a text file:\n\n    # If using a text file\n    \n    addurl(\"AIWork\", path = \"_ai_or_artificial_intelligence___work_or_employment_or_job_or_profession_or_labor_market01.txt\")\n\n-   `path`: The path to a text file containing the URLs to be added.\n", "type": "Text_excerpt", "original_header": "6. Add URLs Manually or Using a File", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    listlands(\"AIWork\")\n\nThis function is used again to list the projects or a specific project,\nensuring that the URLs have been added correctly to \u201cAIWork\u201d.\n", "type": "Text_excerpt", "original_header": "7. List the Projects or a Specific Project", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    deleteland(land_name = \"AIWork\")\n\n\nThe `deleteland()` function deletes a specified project. This can be\nuseful for cleaning up after the research is completed or if a project\nneeds to be restarted.\n\n-   `land_name`: A string specifying the name of the land to delete.\n-   `maxrel`: An integer specifying the maximum relevance for\n    expressions to delete. Default is `NULL`.\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n\nThis script demonstrates the basic setup and execution of a research\nproject using My Web Intelligence, including project creation, term\naddition, URL management, and project verification.\n", "type": "Text_excerpt", "original_header": "8. Optionally Delete a Project", "parent_header": ["Using mwiR : a study case", "Step 1: Creating the Research Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "In this section, we will walk through the process of crawling URLs and\nextracting content for analysis using the My Web Intelligence (MWI)\nmethod. The following R code snippets demonstrate how to perform these\ntasks.\n", "type": "Text_excerpt", "original_header": "Step 2: Crawling", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    crawlurls(\"AIWork\", limit = 10)\n\n\nThe `crawlurls()` function crawls URLs for a specific land, updates the\ndatabase, and calculates relevance scores.\n\n-   `land_name`: A character string representing the name of the land.\n-   `urlmax`: An integer specifying the maximum number of URLs to be\n    processed (default is 50).\n-   `limit`: An optional integer specifying the limit on the number of\n    URLs to crawl.\n-   `http_status`: An optional character string specifying the HTTP\n    status to filter URLs.\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n\n**Example:**\n\nThis example demonstrates crawling up to 10 URLs for the land named\n\n    crawlurls(\"AIWork\", limit = 10)\n\n\n", "type": "Text_excerpt", "original_header": "Crawl URLs for a Specific Land", "parent_header": ["Using mwiR : a study case", "Step 2: Crawling"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    crawlDomain(1000)\n\n\n\nThe `crawlDomain()` function crawls domains and updates the Domain table\nwith the fetched data.\n\n-   `nburl`: An integer specifying the number of URLs to be crawled\n    (default is 100).\n-   `db_name`: A string specifying the name of the SQLite database file.\n    Default is `\"mwi.db\"`.\n\n**Example:**\n\nThis example demonstrates crawling 1000 URLs and updating the Domain\ntable.\n\n    crawlDomain(1000)\n\n    \n", "type": "Text_excerpt", "original_header": "Crawl Domains", "parent_header": ["Using mwiR : a study case", "Step 2: Crawling"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "In this section, we will walk through the process of exporting data and\ncorpora from a research project using the My Web Intelligence (MWI)\nmethod. The following R code snippets demonstrate how to perform these\ntasks.\n", "type": "Text_excerpt", "original_header": "Step 3: Export Files and Corpora", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "    #type = ['pagecsv', 'pagegexf', 'fullpagecsv', 'nodecsv', 'nodegexf', 'mediacsv', 'corpus']\n\n    # Exemple d'utilisation \"le projet\", \"type d'export\", \"relevance\", \"file\"\n    \n    export_land(\"giletsjaunes\", \"pagegexf\", 3)\n\nThe `export_land()` function manages the exportation of land data based\non the specified export type.\n\n-   `land_name`: A character string specifying the name of the land.\n-   `export_type`: A character string specifying the type of export.\n    Options include `\"pagecsv\"`, `\"fullpagecsv\"`, `\"nodecsv\"`,\n    `\"mediacsv\"`, `\"pagegexf\"`, `\"nodegexf\"`, or `\"corpus\"`.\n-   `minimum_relevance`: A numeric value specifying the minimum\n    relevance score for inclusion in the export. Default is `1`.\n-   `labase`: A character string specifying the name of the database\n    file. Default is `\"mwi.db\"`.\n\n**Example:**\n\nThis example demonstrates exporting data for the project \u201cgiletsjaunes\u201d\nwith a minimum relevance score of 3 into a GEXF file.\n\n    export_land(\"giletsjaunes\", \"pagegexf\", 3)\n", "type": "Text_excerpt", "original_header": "Export Land Data", "parent_header": ["Using mwiR : a study case", "Step 3: Export Files and Corpora"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "Once the foundational land is in place, the next objective is to broaden your web perimeter. The package provides dedicated helpers around [SerpAPI](https://serpapi.com/) so you can script keyword expansion and SERP harvesting before every crawl.\n", "type": "Text_excerpt", "original_header": "Step 4: Enrich Your Corpus with SerpAPI Helpers", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nrelated_query(\"intelligence artificielle\", lang = \"fr\", country = \"France\")\n```\n\n`related_query()` returns the \"People also search for\" block as a tidy data frame. Typical workflow: collect the suggestions, inspect them quickly in R, fold the most relevant ones back into `addterm()`, and archive the CSV for methodological transparency.\n", "type": "Text_excerpt", "original_header": "1. Discover Related Queries", "parent_header": ["Using mwiR : a study case", "Step 4: Enrich Your Corpus with SerpAPI Helpers"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nurlist_Google(\n  query = \"ai OR artificial intelligence\",\n  datestart = \"2024-01-01\",\n  dateend   = \"2024-03-31\",\n  timestep  = \"month\",\n  sleep_seconds = 2,\n  lang = \"en\"\n)\n```\n\n`urlist_Google()`, `urlist_Duck()`, and `urlist_Bing()` paginate SERP responses and write raw URL dumps on disk (one file per query). You can then read those files back with `importFile()` and feed them to `addurl()`. Remember to space requests (`sleep_seconds`) to stay inside rate limits.\n", "type": "Text_excerpt", "original_header": "2. Capture Google, DuckDuckGo, and Bing Result Lists", "parent_header": ["Using mwiR : a study case", "Step 4: Enrich Your Corpus with SerpAPI Helpers"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nmwir_seorank(\n  filename = \"aiwatch_seo\",\n  urls     = c(\"example.com\", \"opencorpus.org\"),\n  api_key  = Sys.getenv(\"SEORANK_API_KEY\")\n)\n```\n\n`mwir_seorank()` queries the SEO Rank API for MOZ/PageSpeed style indicators. Because the function appends rows as soon as a response arrives, you can launch it overnight on dozens of domains and obtain a ready-to-share CSV.\n", "type": "Text_excerpt", "original_header": "3. Monitor SEO Signals", "parent_header": ["Using mwiR : a study case", "Step 4: Enrich Your Corpus with SerpAPI Helpers"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "When the time comes to model or discretise quantitative indicators (e.g., in-degree, frequency, sentiment scores), the package offers statistical helpers inspired by social-science workflows.\n", "type": "Text_excerpt", "original_header": "Step 5: Transform and Diagnose Numeric Variables", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nplotlog(\n  df         = analytics,\n  variables  = c(\"in_degree\", \"reach\"),\n  trans_type = c(in_degree = \"log1p\", reach = \"zscore\"),\n  save       = TRUE\n)\n```\n`plotlog()` overlays the original and transformed histograms so you can compare scales immediately. Main arguments and expected inputs:\n\n- `df` \u2014 data frame passed to the function. If you leave `variables = NULL`, every **numeric** column in `df` is analysed.\n- `variables` \u2014 character vector that specifies the columns to plot. You can supply a named vector or list so each variable receives its own transformation rule.\n- `trans_type` \u2014 transformation applied to each series. Recognised keywords: `\"none\"`, `\"log\"`, `\"log1p\"`, `\"sqrt\"`, `\"rank\"`, `\"zscore\"`. Provide a single value to reuse it everywhere, a named vector/list to mix them, or a custom function returning a numeric vector.\n- `bins` \u2014 histogram resolution. Accept an integer (e.g. `30`) or one of the standard rules: `\"sturges\"` (default), `\"fd\"`/`\"freedman-diaconis\"`, `\"scott\"`, `\"sqrt\"`, `\"rice\"`, `\"doane\"`, `\"auto\"` (maximum of Sturges and F-D).\n- `colors`, `alpha` \u2014 choose the two fill colours (original vs transformed) and set the transparency level between 0 and 1.\n- `theme` \u2014 any `ggplot2` theme object (`theme_minimal()` by default).\n- `density`, `show_rug` \u2014 booleans that toggle a kernel density overlay and a rug showing individual points.\n- `na_rm`, `min_non_missing` \u2014 control filtering. `na_rm = TRUE` drops non-finite values before plotting; `min_non_missing` (default 5) is the minimum number of finite values required for a variable to be plotted.\n- `shift_constant` \u2014 positive offset automatically added before log/sqrt transformations when the data contains zero or negative values (default 1).\n- `display` \u2014 `TRUE` prints the combined panel to the current graphics device; set to `FALSE` to return the object silently.\n- `save` \u2014 set to `TRUE` to export the plots. Use with `save_dir` (folder), `save_format` (`\"png\"`, `\"pdf\"`, or `\"jpg\"`), `save_dpi`, `device_width`, and `device_height` to control the files that are written.\n- `verbose` \u2014 produces progress messages when `TRUE` (defaults to `interactive()`).\n", "type": "Text_excerpt", "original_header": "1. Explore Transformations Visually", "parent_header": ["Using mwiR : a study case", "Step 5: Transform and Diagnose Numeric Variables"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nscaled <- transform_variable(\n  x         = analytics$reach,\n  method    = \"yeojohnson\",\n  winsorize = 0.01\n)\n```\n\n`transform_variable()` stores both the transformed values and the inverse mapping. This makes it easy to export model-ready columns while keeping de-standardisation metadata.\n\n- `x` \u2014 numeric vector to transform (NA/Inf allowed; non-finite entries propagate).\n- `method` \u2014 transformation choice: `\"auto\"` (bestNormalize search), `\"none\"`, `\"center\"`, `\"zscore\"`, `\"robust_z\"`, `\"log\"`, `\"log1p\"`, `\"sqrt\"`, `\"boxcox\"`, `\"yeojohnson\"`, `\"ranknorm\"`, or a user-supplied function.\n- `winsorize` \u2014 optional share of tails to trim before transforming (0 \u2264 value < 0.5). Use `NULL` to skip.\n- `shift_constant` \u2014 positive constant automatically added before log/sqrt transforms when `x` contains non-positive values (default 1).\n- `handle_na` \u2014 choose `\"keep\"` (default) to leave NA in place or `\"omit\"` to drop them before fitting the transform.\n- `...` \u2014 forwarded to `bestNormalize` helpers (e.g. Box-Cox tweaks) when the selected method requires it.\n", "type": "Text_excerpt", "original_header": "2. Apply Robust Transformations Programmatically", "parent_header": ["Using mwiR : a study case", "Step 5: Transform and Diagnose Numeric Variables"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nclusters <- find_clusters(\n  analytics$reach,\n  max_G         = 5,\n  transform     = \"auto\",\n  winsorize     = 0.01,\n  return_breaks = TRUE\n)\n\nclasses <- discretize_variable(\n  analytics$reach,\n  method = \"manual\",\n  breaks = clusters$breaks,\n  labels = c(\"Faible\", \"Moyen\", \"\u00c9lev\u00e9\")\n)\n```\n\n- `find_clusters()` ajuste des m\u00e9langes gaussiens 1D pour r\u00e9v\u00e9ler des typologies. Param\u00e8tres essentiels\u00a0: `max_G` (nombre de composantes), `criterion` (`\"bic\"` ou `\"icl\"`), `transform` (`\"none\"`, `\"log1p\"`, `\"yeojohnson\"`, `\"zscore\"`, `\"auto\"`) et `winsorize` (0\u20130.5). Avec `return_breaks = TRUE`, la fonction fournit des bornes pr\u00eates \u00e0 l\u2019emploi et expose la `classification`, les probabilit\u00e9s `posterior`, `n_clusters` et plusieurs diagnostics.\n- `discretize_variable()` transforme ensuite la mesure continue en classes interpr\u00e9tables. Les m\u00e9thodes disponibles (`\"equal_freq\"`, `\"equal_width\"`, `\"quantile\"`, `\"jenks\"`, `\"kmeans\"`, `\"gmm\"`, `\"manual\"`) couvrent la plupart des sc\u00e9narios. En mode `\"manual\"`, fournissez vos `breaks` (ceux du clustering, par exemple) et des `labels` parlants. Le facteur retourn\u00e9 reste ordonn\u00e9 et conserve un attribut `discretize_meta` (bornes, effectifs, avertissements).\n", "type": "Text_excerpt", "original_header": "3. Segment Indicators into Meaningful Classes", "parent_header": ["Using mwiR : a study case", "Step 5: Transform and Diagnose Numeric Variables"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\npowerlaw <- analyse_powerlaw(\n  analytics$reach,\n  type             = \"discrete\",\n  candidate_models = c(\"powerlaw\", \"lognormal\", \"exponential\"),\n  bootstrap_sims   = 200,\n  winsorize        = 0.01,\n  threads          = 4\n)\n```\n\n- `analyse_powerlaw()` confronte plusieurs lois de queue pour tester la pr\u00e9sence d\u2019une v\u00e9ritable loi de puissance.\n- En mode `\"discrete\"`, les donn\u00e9es sont arrondies et les valeurs < 1 exclues ; v\u00e9rifie qu\u2019il reste assez d\u2019observations positives (`min_n` = 50 par d\u00e9faut).\n- Ajuste `type`, `candidate_models`, `winsorize`, `xmin` et `threads` (nombre de c\u0153urs utilis\u00e9s pendant le bootstrap) selon tes besoins de robustesse et de temps de calcul.\n- `candidate_models` accepte `\"powerlaw\"`, `\"lognormal\"`, `\"exponential\"` (et `\"weibull\"` en continu). Tu peux fournir un sous-ensemble cibl\u00e9 ou changer l\u2019ordre selon les lois pertinentes pour ton terrain.\n- `bootstrap_sims` contr\u00f4le le nombre de simulations KS, `bootstrap_models` restreint la liste des mod\u00e8les simul\u00e9s. Diminue `bootstrap_sims` pour un r\u00e9sultat rapide, augmente-le pour plus de pr\u00e9cision.\n- La sortie regroupe `best_model`, les param\u00e8tres (`best_fit`), les comparaisons de vraisemblance (`comparisons`), les diagnostics bootstrap (`bootstrap`) et un `data_summary` directement mobilisable dans les rapports.\n- Bonnes pratiques : essayer plusieurs `winsorize`, surveiller `best_fit$n_tail`, examiner les p-values bootstrap et justifier le `xmin` retenu.\n", "type": "Text_excerpt", "original_header": "4. Examine Heavy-Tailed Behaviours", "parent_header": ["Using mwiR : a study case", "Step 5: Transform and Diagnose Numeric Variables"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "Large Language Models can speed up qualitative coding, but they demand guardrails.\n\n```r\nSys.setenv(OPENAI_API_KEY = \"sk-...\")\ngpt_out <- GPT_Recode(\n  prompt      = \"Traduire en fran\u00e7ais\",\n  cell        = \"Automation and labour markets\",\n  model       = \"gpt-4o\",\n  temperature = 0.4,\n  max_tokens  = 120\n)\n\nSys.setenv(OPENROUTER_API_KEY = \"orpk-...\")\nor_out <- OpenRouter_Recode(\n  prompt          = \"R\u00e9sumer en 20 mots\",\n  cell            = \"The platform reorganised work across the supply chain\",\n  model           = \"openrouter/auto/gpt-4\",\n  temperature     = 0.2,\n  max_tokens      = 80,\n  return_metadata = TRUE\n)\n```\n\n**Entr\u00e9es de `GPT_Recode()`**  \n- `prompt` : instruction textuelle (obligatoire).  \n- `cell` : contenu \u00e0 transformer, cha\u00eene unique.  \n- `sysprompt` : message syst\u00e8me qui cadre la r\u00e9ponse.  \n- `model` : moteur OpenAI (`\"gpt-4o\"`, `\"gpt-4o-mini\"`, etc.).  \n- `temperature` (0\u20132) : al\u00e9a de g\u00e9n\u00e9ration.  \n- `max_tokens` : plafond de tokens en sortie.  \n- `max_retries`, `retry_delay` : nombre de relances et d\u00e9lai entre elles.  \n- `validate` : filtre la r\u00e9ponse (longueur raisonnable, pas d\u2019excuses).  \n> **Prerequis** : d\u00e9finir `OPENAI_API_KEY` avant d\u2019appeler la fonction.\n\n**Sortie**  \n- Une cha\u00eene recod\u00e9e, ou `NA` si l\u2019appel \u00e9choue malgr\u00e9 les relances (un `warning` est \u00e9mis).\n\n**Entr\u00e9es de `OpenRouter_Recode()`**  \n- m\u00eames arguments que ci-dessus (`prompt`, `cell`, `sysprompt`, `model`, `temperature`, `max_tokens`, `max_retries`, `retry_delay`, `validate`).  \n- `referer`, `title` : en-t\u00eates requis par OpenRouter.  \n- `api_base` : URL de l\u2019endpoint (par d\u00e9faut `https://openrouter.ai/api/v1/chat/completions`).  \n- `timeout` : dur\u00e9e max de la requ\u00eate.  \n- `extra_headers` : en-t\u00eates additionnels (vecteur nomm\u00e9).  \n- `return_metadata` : bascule entre cha\u00eene simple et liste enrichie.  \n> **Prerequis** : `OPENROUTER_API_KEY` doit \u00eatre d\u00e9fini et les packages `httr`, `jsonlite` install\u00e9s.\n\n**Sortie**  \n- Par d\u00e9faut, une cha\u00eene.  \n- Avec `return_metadata = TRUE`, une liste compos\u00e9e de `value`, `status` (tentatives, validation) et `http` (code, en-t\u00eates). Les champs sont `NA` en cas d\u2019\u00e9chec.\n\n**Bonnes pratiques**  \n- Documenter `prompt`, `sysprompt`, mod\u00e8le et version dans votre carnet de labo.  \n- Baisser `temperature` pour des traductions fid\u00e8les, l\u2019augmenter pour des reformulations cr\u00e9atives.  \n- Limiter `max_tokens` pour garder des r\u00e9ponses concises.  \n- G\u00e9rer les `NA` dans vos scripts (`if (is.na(gpt_out)) \u2026`) et surveiller les quotas des fournisseurs.\n", "type": "Text_excerpt", "original_header": "Step 8: Leverage AI Assistance Responsibly", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "The database layer underpins every land. The following helpers keep it healthy and synchronised with external edits.\n", "type": "Text_excerpt", "original_header": "Step 9: Maintain the Database Throughout the Project Lifecycle", "parent_header": ["Using mwiR : a study case"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\ncon      <- connect_db()\nland_id  <- get_land_id(con, \"AIWork\")\ndomaines <- list_domain(con, land_name = \"AIWork\")\n```\n\n- `connect_db()` returns a ready-to-use `DBI` connection.\n- `get_land_id()` converts human-readable land names into numeric IDs when you automate workflows.\n- `list_domain()` produces a domain summary (counts, keywords) to monitor coverage.\n", "type": "Text_excerpt", "original_header": "1. Connect Programmatically and Reuse IDs", "parent_header": ["Using mwiR : a study case", "Step 9: Maintain the Database Throughout the Project Lifecycle"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nurls <- importFile()\naddurl(\"AIWork\", urls = urls$url)\n```\n\nUse `importFile()` whenever you enrich your corpus from spreadsheets or open postings. The helper returns a data frame; pass the relevant column to `addurl()`.\n", "type": "Text_excerpt", "original_header": "2. Import Additional Material", "parent_header": ["Using mwiR : a study case", "Step 9: Maintain the Database Throughout the Project Lifecycle"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "```r\nannotatedData(\n  dataplus = curated_notes,\n  table    = \"Expression\",\n  champ    = \"description\",\n  by       = \"id\"\n)\n```\n\n`annotatedData()` wraps transactional updates so a batch edit either fully succeeds or rolls back. Always back up `mwi.db` before bulk reinsertion.\n", "type": "Text_excerpt", "original_header": "3. Reinstate Externally Annotated Data", "parent_header": ["Using mwiR : a study case", "Step 9: Maintain the Database Throughout the Project Lifecycle"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}, {"result": {"value": "Beyond `export_land()`, the family of dedicated exporters gives you fine-grained control:\n\n- `export_pagecsv()` and `export_fullpagecsv()` to share tabular corpora.\n- `export_nodecsv()` / `export_nodegexf()` for network analysis.\n- `export_mediacsv()` to audit associated media.\n- `export_pagegexf()` for expression-level graphs.\n- `export_corpus()` to assemble text files plus metadata headers (ideal for CAQDAS tools).\n\nEach exporter accepts `minimum_relevance`, so you can balance breadth and focus depending on the audience.", "type": "Text_excerpt", "original_header": "4. Export Precisely What You Need", "parent_header": ["Using mwiR : a study case", "Step 9: Maintain the Database Throughout the Project Lifecycle"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}], "documentation": [{"result": {"value": "**NAKALA Repositories** The data and results of the MWI project are\ndeposited on the NAKALA platform, providing open access for other\nresearchers and practitioners. Here are some important repositories:\n\n1.  [The\n    collection](https://nakala.fr/collection/10.34847/nkl.b4aarv3j):\n    Contains a detailed description of the project, methodology, and\n    results.\n2.  [Positions and Influences on the Web: The Case of Health\n    Information](https://nakala.fr/prise-de-position): Detailed analysis\n    of discourses on childhood asthma.\n3.  [French Digital Humanities\n    communities](https://nakala.fr/10.34847/nkl.f43by03n): A study case\n    on French digital humanities development on the web.\n", "type": "Text_excerpt", "original_header": "Repositories and Documentation", "parent_header": ["mwiR 0.9.0 (Beta) The R Package of My Web Intelligence Project"]}, "confidence": 1, "technique": "header_analysis", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}], "full_title": [{"result": {"type": "String", "value": "mwiR 0.9.0 (Beta) The R Package of My Web Intelligence Project"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}], "images": [{"result": {"type": "Url", "value": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/man/figures/mwibanner.png"}, "confidence": 1, "technique": "regular_expression", "source": "https://raw.githubusercontent.com/MyWebIntelligence/mwiR/main/README.Rmd"}]}